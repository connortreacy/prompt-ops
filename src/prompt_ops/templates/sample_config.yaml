# Prompt-ops Project Configuration
# Generated by: prompt-ops create <project-name>

system_prompt:
  file: prompts/prompt.txt
  inputs:
    - question
  outputs:
    - answer

dataset:
  path: data/dataset.json
  input_field:
    - fields
    - input
  golden_output_field: answer

model:
  # Model names use provider/model format (e.g., openrouter/meta-llama/llama-3.3-70b-instruct)
  task_model: ${MODEL}
  proposer_model: ${MODEL}
  # Rate limit handling for APIs with request limits
  rate_limit:
    max_retries: 10      # Number of retry attempts for rate limit errors
    initial_delay: 30    # Initial delay in seconds (doubles each retry)
    max_delay: 300       # Maximum delay cap in seconds (5 minutes)

metric:
  class: prompt_ops.core.metrics.FacilityMetric
  strict_json: false
  output_field: answer

optimization:
  strategy: basic
  num_threads: 2  # Reduce for rate-limited APIs
